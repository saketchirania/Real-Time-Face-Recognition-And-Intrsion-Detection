{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    cv2.imshow('frame', frame)\n",
    "    cv2.imshow('gray', gray)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "url = 'http://192.168.43.32:8080/'\n",
    "\n",
    "cam = cv2.VideoCapture(url)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    cv2.imshow('frame', frame)\n",
    "    #cv2.imshow('gray', gray)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detection of Faces\n",
    "\n",
    "faceCascade = cv2.CascadeClassifier('C:\\\\Users\\\\Paras\\\\Anaconda3\\\\envs\\\\py36\\\\Library\\\\etc\\\\haarcascades\\\\haarcascade_frontalface_default.xml')\n",
    "\n",
    "#url = 'http://192.168.43.32:8080/'\n",
    "\n",
    "#cam = cv2.VideoCapture(url)\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, img = cam.read()\n",
    "    img = cv2.flip(img, 1)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.2,\n",
    "        minNeighbors=5,\n",
    "        minSize = (22,22)\n",
    "    )\n",
    "    \n",
    "    for(x,y,w,h) in faces:\n",
    "        cv2.rectangle(img, (x,y),(x+w, y+h), (0,255,255),2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]\n",
    "        \n",
    "        \n",
    "    cv2.imshow('capturing', img)\n",
    "    \n",
    "    esc = cv2.waitKey(30) & 0xFF\n",
    "    if esc == 27:\n",
    "        break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter name of person : umadevi\n",
      "\n",
      " Starting up... \n",
      " Look at the camera and wait...\n",
      "\n",
      " Exiting Trainer...\n"
     ]
    }
   ],
   "source": [
    "# Capturing Faces and Labelling them\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "url = 'http://192.168.43.32:8080/'\n",
    "\n",
    "#cam = cv2.VideoCapture(url)\n",
    "cam = cv2.VideoCapture(0)\n",
    "cam.set(3, 640)\n",
    "cam.set(4, 480)\n",
    "\n",
    "face_detector = cv2.CascadeClassifier('C:\\\\Users\\\\Paras\\\\Anaconda3\\\\envs\\\\py36\\\\Library\\\\etc\\\\haarcascades\\\\haarcascade_frontalface_default.xml')\n",
    "\n",
    "face_id = input(\"Enter name of person : \")\n",
    "face_id = face_id.lower()\n",
    "\n",
    "temp = os.getcwd()\n",
    "path = \"\\\\face_count\\\\\" + face_id + \".txt\"\n",
    "temp = temp+path\n",
    "check = os.path.exists(temp)\n",
    "\n",
    "id = 0\n",
    "count = 0\n",
    "\n",
    "if check:\n",
    "    f = open(temp, 'r')\n",
    "    id = int(f.readline())\n",
    "    count = int(f.readline())\n",
    "    f.close()\n",
    "else:\n",
    "    p = os.getcwd()\n",
    "    p = p + '\\\\face_count\\\\id.txt'\n",
    "    id_file = open(p, 'r')\n",
    "    id = int(id_file.read())\n",
    "    #print(type(id))\n",
    "    id_file.close()\n",
    "    \n",
    "    id_file = open(p, 'w')\n",
    "    new_id = str(id+1)\n",
    "    id_file.write(new_id)\n",
    "    id_file.close()\n",
    "    \n",
    "    f = open(temp, 'w')\n",
    "    f.write(str(id))\n",
    "    count = 0\n",
    "    f.close()\n",
    "\n",
    "print(\"\\n Starting up... \\n Look at the camera and wait...\")\n",
    "\n",
    "iters = 0\n",
    "while(True):\n",
    "    ret, img = cam.read()\n",
    "    img = cv2.flip(img, 1)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_detector.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img, (x,y), (x+w,y+h), (0,255,255), 2)     \n",
    "        iters += 1\n",
    "\n",
    "        cv2.imwrite(\"face_data/User.\" + str(id) + '.' + face_id + '.' + \n",
    "                    str(count+iters) + \".jpg\", gray[y:y+h,x:x+w])\n",
    "\n",
    "        cv2.imshow('Face Capturing', img)\n",
    "\n",
    "    esc = cv2.waitKey(30) & 0xFF\n",
    "    if esc == 27:\n",
    "        break\n",
    "    elif iters >= 10:\n",
    "         break\n",
    "    \n",
    "count += iters\n",
    "f = open(temp,'w')\n",
    "f.write(str(id)+'\\n'+str(count))\n",
    "f.close()\n",
    "\n",
    "print(\"\\n Exiting Trainer...\")\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Training faces....\n",
      "\n",
      " 3 faces trained.\n"
     ]
    }
   ],
   "source": [
    "# Training the faces with their labels\n",
    "\n",
    "\n",
    "path = 'face_data'\n",
    "\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "#recognizer = cv2.face.FisherFaceRecognizer_create()\n",
    "\n",
    "detector = cv2.CascadeClassifier(\"C:\\\\Users\\\\Paras\\\\Anaconda3\\\\envs\\\\py36\\\\Library\\\\etc\\\\haarcascades\\\\haarcascade_frontalface_default.xml\");\n",
    "\n",
    "label_to_name= {}\n",
    "img_numpy = []\n",
    "def images_labels(path):\n",
    "    imagePaths = [os.path.join(path,f) for f in os.listdir(path)]     \n",
    "    faceSamples=[]\n",
    "    ids = []\n",
    "    for imagePath in imagePaths:\n",
    "        PIL_img = Image.open(imagePath).convert('L')\n",
    "        img_numpy = np.array(PIL_img,'uint8')\n",
    "        id = int(os.path.split(imagePath)[-1].split(\".\")[1])\n",
    "        name = os.path.split(imagePath)[-1].split(\".\")[2]\n",
    "        if id not in label_to_name:\n",
    "            label_to_name[id] = name\n",
    "        faces = detector.detectMultiScale(img_numpy)\n",
    "        for (x,y,w,h) in faces:\n",
    "            faceSamples.append(img_numpy[y:y+h,x:x+w])\n",
    "            ids.append(id)\n",
    "    return faceSamples,ids\n",
    "\n",
    "print (\"\\n Training faces....\")\n",
    "faces,ids = images_labels(path)\n",
    "recognizer.train(faces, np.array(ids))\n",
    "\n",
    "recognizer.write('trainer/trainer.yml')\n",
    "\n",
    "print(\"\\n {0} faces trained.\".format(len(np.unique(ids))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SerialException",
     "evalue": "could not open port 'com12': FileNotFoundError(2, 'The system cannot find the file specified.', None, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSerialException\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-15aacb98280e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mserial\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mArduino_Serial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mserial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'com12'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m9600\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mrecognizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mface\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLBPHFaceRecognizer_create\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\serial\\serialwin32.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_overlapped_read\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_overlapped_write\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSerial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\serial\\serialutil.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, port, baudrate, bytesize, parity, stopbits, timeout, xonxoff, rtscts, write_timeout, dsrdtr, inter_byte_timeout, exclusive, **kwargs)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mport\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 240\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[1;31m#  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\serial\\serialwin32.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_port_handle\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mwin32\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mINVALID_HANDLE_VALUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_port_handle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m    \u001b[1;31m# 'cause __del__ is called anyway\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mSerialException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"could not open port {!r}: {!r}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mportstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWinError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSerialException\u001b[0m: could not open port 'com12': FileNotFoundError(2, 'The system cannot find the file specified.', None, 2)"
     ]
    }
   ],
   "source": [
    "# Real time face recognizer\n",
    "\n",
    "import serial\n",
    "Arduino_Serial = serial.Serial('com12',9600)\n",
    "\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "#recognizer = cv2.face.BasicFaceRecognizer_create()\n",
    "recognizer.read('trainer/trainer.yml')\n",
    "cascadePath = \"C:\\\\Users\\\\Paras\\\\Anaconda3\\\\envs\\\\py36\\\\Library\\\\etc\\\\haarcascades\\\\haarcascade_frontalface_default.xml\"\n",
    "faceCascade = cv2.CascadeClassifier(cascadePath);\n",
    "\n",
    "font = cv2.FONT_HERSHEY_DUPLEX\n",
    "\n",
    "id = 0\n",
    "\n",
    "# Initialize and start realtime video capture\n",
    "#url = 'http://192.168.0.3:8080/'\n",
    "\n",
    "#cam = cv2.VideoCapture(url)\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "cam.set(3, 640)\n",
    "cam.set(4, 480)\n",
    "\n",
    "minW = 0.1*cam.get(3)\n",
    "minH = 0.1*cam.get(4)\n",
    "fps = cam.get(5)\n",
    "count = 0\n",
    "flag = 0\n",
    "\n",
    "while True:\n",
    "    ret, img = cam.read()\n",
    "    img = cv2.flip(img, 1)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces = faceCascade.detectMultiScale( \n",
    "        gray,\n",
    "        scaleFactor = 1.2,\n",
    "        minNeighbors = 5,\n",
    "        minSize = (int(minW), int(minH)),\n",
    "       )\n",
    "    \n",
    "    for(x,y,w,h) in faces:\n",
    "        cv2.rectangle(img, (x,y), (x+w,y+h), (0,255,255), 2)\n",
    "        id, confidence = recognizer.predict(gray[y:y+h,x:x+w])\n",
    "\n",
    "        # Check if confidence is less than 100 ==> \"0\" is perfect match \n",
    "        if (confidence < 60):\n",
    "            name = label_to_name[id]\n",
    "            confidence = \"  {0}%\".format(round(100 - confidence))\n",
    "            count+=1\n",
    "        else:\n",
    "            name = \"\"\n",
    "            confidence = \"  {0}%\".format(round(100 - confidence))\n",
    "            count=0\n",
    "        \n",
    "        cv2.putText(img, str(name), (x+5,y-5), font, 1, (255,255,255), 2)\n",
    "        #cv2.putText(img, str(confidence), (x+5,y+h-5), font, 1, (255,255,0), 1)  \n",
    "        cv2.putText(img, str(fps), (30,30), font, 1, (255,255,255), 1)\n",
    "        if name != \"\":\n",
    "            cv2.putText(img, str(count), (100,100), font, 1, (255,255,255),2)\n",
    "                    \n",
    "        if count > 20:\n",
    "            cv2.putText(img, \"Hello \"+str(name)+\"!\", (50,50), font, 1, (255,255,255),2)            \n",
    "            Arduino_Serial.write('1')\n",
    "    \n",
    "    cv2.imshow('Recognizer',img) \n",
    "        \n",
    "    esc = cv2.waitKey(30) & 0xFF\n",
    "    if esc == 27:\n",
    "        break\n",
    "            \n",
    "print(\"\\n Exiting Recognizer...\")\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "SerialException",
     "evalue": "could not open port 'com12': FileNotFoundError(2, 'The system cannot find the file specified.', None, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSerialException\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-d07556e27e33>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mserial\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mArduino_Serial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mserial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'com12'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m9600\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mArduino_Serial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\serial\\serialwin32.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_overlapped_read\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_overlapped_write\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSerial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\serial\\serialutil.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, port, baudrate, bytesize, parity, stopbits, timeout, xonxoff, rtscts, write_timeout, dsrdtr, inter_byte_timeout, exclusive, **kwargs)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mport\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 240\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[1;31m#  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\serial\\serialwin32.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_port_handle\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mwin32\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mINVALID_HANDLE_VALUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_port_handle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m    \u001b[1;31m# 'cause __del__ is called anyway\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mSerialException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"could not open port {!r}: {!r}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mportstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWinError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSerialException\u001b[0m: could not open port 'com12': FileNotFoundError(2, 'The system cannot find the file specified.', None, 2)"
     ]
    }
   ],
   "source": [
    "import serial\n",
    "Arduino_Serial = serial.Serial('com12',9600)\n",
    "Arduino_Serial.write('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Connection established...\\r\\n'\n",
      "Enter 1 to ON LED and 0 to OFF LED\n",
      "1\n",
      "you entered 1\n",
      "LED ON\n",
      "0\n",
      "you entered 0\n",
      "LED OFF\n",
      "1\n",
      "you entered 1\n",
      "LED ON\n",
      "1\n",
      "you entered 1\n",
      "LED ON\n",
      "0\n",
      "you entered 0\n",
      "LED OFF\n"
     ]
    }
   ],
   "source": [
    "import serial                                 \n",
    "\n",
    "Arduino_Serial = serial.Serial('com3',9600)  #Create Serial port object called arduinoSerialData\n",
    "\n",
    "print (Arduino_Serial.readline())               #read the serial data and print it as line\n",
    "\n",
    "print (\"Enter 1 to ON LED and 0 to OFF LED\")\n",
    "\n",
    "\n",
    "\n",
    "while 1:                                      #infinite loop\n",
    "\n",
    "    input_data = input()                  #waits until user enters data\n",
    "\n",
    "    print (\"you entered\", input_data)           #prints the data for confirmation\n",
    "\n",
    "    \n",
    "\n",
    "    if (input_data == '1'):                   #if the entered data is 1 \n",
    "\n",
    "        Arduino_Serial.write(b'1')             #send 1 to arduino\n",
    "\n",
    "        print (\"LED ON\")\n",
    "\n",
    "       \n",
    "\n",
    "    \n",
    "\n",
    "    if (input_data == '0'):                   #if the entered data is 0\n",
    "\n",
    "        Arduino_Serial.write(b'0')             #send 0 to arduino \n",
    "\n",
    "        print (\"LED OFF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter name of person : paras\n"
     ]
    }
   ],
   "source": [
    "face_id = input(\"Enter name of person : \")\n",
    "face_id = face_id.lower()\n",
    "\n",
    "temp = os.getcwd()\n",
    "path = \"\\\\face_count\\\\\" + face_id + \".txt\"\n",
    "temp = temp+path\n",
    "check = os.path.exists(temp)\n",
    "\n",
    "id = 0\n",
    "count = 0\n",
    "\n",
    "if check:\n",
    "    f = open(temp, 'r')\n",
    "    id = f.readline()\n",
    "    count = f.readline()\n",
    "    f.close()\n",
    "else:\n",
    "    p = os.getcwd()\n",
    "    p = p + '\\\\face_count\\\\id.txt'\n",
    "    id_file = open(p, 'r')\n",
    "    id = int(id_file.read())\n",
    "    #print(type(id))\n",
    "    id_file.close()\n",
    "    \n",
    "    id_file = open(p, 'w')\n",
    "    new_id = str(id+1)\n",
    "    id_file.write(new_id)\n",
    "    id_file.close()\n",
    "    \n",
    "    f = open(temp, 'w')\n",
    "    f.write(str(id))\n",
    "    count = 0\n",
    "    f.close()\n",
    "    \n",
    "    \n",
    "#print(id)\n",
    "#print(count)\n",
    "\n",
    "\n",
    "f = open(temp,'w')\n",
    "f.write(str(id)+'\\n'+str(count))\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24, 23, 24, ..., 31, 30, 27],\n",
       "       [24, 23, 23, ..., 31, 31, 30],\n",
       "       [24, 22, 21, ..., 32, 32, 33],\n",
       "       ...,\n",
       "       [53, 58, 62, ...,  4,  4,  5],\n",
       "       [54, 60, 65, ...,  4,  4,  5],\n",
       "       [54, 61, 67, ...,  4,  4,  5]], dtype=uint8)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ipath='C:\\\\Users\\\\Paras\\\\Anaconda3\\\\envs\\\\py36\\\\face_data\\\\User.1.paras.27.jpg'\n",
    "PIL_img = Image.open(Ipath).convert('L')\n",
    "img_numpy = np.array(PIL_img,'uint8')\n",
    "img_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os, sys\n",
    "\n",
    "path = \"C:\\\\Users\\\\Paras\\\\Anaconda3\\\\envs\\\\py36\\\\face_data\\\\\"\n",
    "dirs = os.listdir(path)\n",
    "final_size = 150;\n",
    "\n",
    "def resize_aspect_fit():\n",
    "    for item in dirs:\n",
    "        if item == '.DS_Store':\n",
    "            continue\n",
    "        if os.path.isfile(path+item):\n",
    "            im = Image.open(path+item)\n",
    "            f, e = os.path.splitext(path+item)\n",
    "            size = im.size\n",
    "            ratio = float(final_size) / max(size)\n",
    "            new_image_size = tuple([int(x*ratio) for x in size])\n",
    "            im = im.resize(new_image_size, Image.ANTIALIAS)\n",
    "            new_im = Image.new(\"RGB\", (final_size, final_size))\n",
    "            new_im.paste(im, ((final_size-new_image_size[0])//2, (final_size-new_image_size[1])//2))\n",
    "            new_im.save(f + '.jpg', 'JPEG', quality=90)\n",
    "resize_aspect_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter name of person : SAKet\n",
      "\n",
      " Starting up... \n",
      " Look at the camera and wait...\n",
      "\n",
      " Exiting Trainer...\n"
     ]
    }
   ],
   "source": [
    "# Detection of Faces\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import time\n",
    "import requests\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "cam.set(3, 640)\n",
    "cam.set(4, 480)\n",
    "\n",
    "face_detector = cv2.CascadeClassifier('C:\\\\Users\\\\Paras\\\\Anaconda3\\\\envs\\\\py36\\\\Library\\\\etc\\\\haarcascades\\\\haarcascade_frontalface_default.xml')\n",
    "\n",
    "face_id = input(\"Enter name of person : \")\n",
    "face_id = face_id.lower()\n",
    "\n",
    "temp = os.getcwd()\n",
    "path = \"\\\\face_count\\\\\" + face_id + \".txt\"\n",
    "temp = temp+path\n",
    "check = os.path.exists(temp)\n",
    "\n",
    "id = 0\n",
    "count = 0\n",
    "\n",
    "if check:\n",
    "    f = open(temp, 'r')\n",
    "    id = int(f.readline())\n",
    "    count = int(f.readline())\n",
    "    f.close()\n",
    "else:\n",
    "    p = os.getcwd()\n",
    "    p = p + '\\\\face_count\\\\id.txt'\n",
    "    id_file = open(p, 'r')\n",
    "    id = int(id_file.read())\n",
    "    #print(type(id))\n",
    "    id_file.close()\n",
    "    \n",
    "    id_file = open(p, 'w')\n",
    "    new_id = str(id+1)\n",
    "    id_file.write(new_id)\n",
    "    id_file.close()\n",
    "    \n",
    "    f = open(temp, 'w')\n",
    "    f.write(str(id))\n",
    "    count = 0\n",
    "    f.close()\n",
    "\n",
    "print(\"\\n Starting up... \\n Look at the camera and wait...\")\n",
    "\n",
    "iters = 0\n",
    "flag = 1\n",
    "url = 'http://192.168.43.125:8080/shot.jpg'\n",
    "\n",
    "while True:\n",
    "    #ret, img = cap.read()\n",
    "    url = 'http://192.168.43.125:8080/shot.jpg'\n",
    "    img_resp = requests.get(url)\n",
    "    img_arr = np.array(bytearray(img_resp.content), dtype=np.uint8)\n",
    "    imgg = cv2.imdecode(img_arr, -1)\n",
    "    img = cv2.flip(imgg, 1)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_detector.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img, (x,y), (x+w,y+h), (0,255,255), 2)     \n",
    "        iters += 1\n",
    "\n",
    "        cv2.imwrite(\"face_data/User.\" + str(id) + '.' + face_id + '.' + str(count+iters) + \".jpg\", gray[y:y+h,x:x+w])\n",
    "\n",
    "        cv2.imshow('image', img)\n",
    "\n",
    "    esc = cv2.waitKey(30) & 0xFF\n",
    "    if esc == 27:\n",
    "        break\n",
    "    elif iters >= 20:\n",
    "         break\n",
    "    \n",
    "count += iters\n",
    "f = open(temp,'w')\n",
    "f.write(str(id)+'\\n'+str(count))\n",
    "f.close()\n",
    "\n",
    "print(\"\\n Exiting Trainer...\")\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Training faces....\n",
      "\n",
      " 2 faces trained. Exiting Program...\n"
     ]
    }
   ],
   "source": [
    "# Training the faces with their labels\n",
    "\n",
    "\n",
    "path = 'face_data'\n",
    "\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "#recognizer = cv2.face.FisherFaceRecognizer_create()\n",
    "\n",
    "detector = cv2.CascadeClassifier(\"C:\\\\Users\\\\Paras\\\\Anaconda3\\\\envs\\\\py36\\\\Library\\\\etc\\\\haarcascades\\\\haarcascade_frontalface_default.xml\");\n",
    "\n",
    "label_to_name= {}\n",
    "img_numpy = []\n",
    "def images_labels(path):\n",
    "    imagePaths = [os.path.join(path,f) for f in os.listdir(path)]     \n",
    "    faceSamples=[]\n",
    "    ids = []\n",
    "    for imagePath in imagePaths:\n",
    "        PIL_img = Image.open(imagePath).convert('L')\n",
    "        img_numpy = np.array(PIL_img,'uint8')\n",
    "        id = int(os.path.split(imagePath)[-1].split(\".\")[1])\n",
    "        name = os.path.split(imagePath)[-1].split(\".\")[2]\n",
    "        if id not in label_to_name:\n",
    "            label_to_name[id] = name\n",
    "        faces = detector.detectMultiScale(img_numpy)\n",
    "        for (x,y,w,h) in faces:\n",
    "            faceSamples.append(img_numpy[y:y+h,x:x+w])\n",
    "            ids.append(id)\n",
    "    return faceSamples,ids\n",
    "\n",
    "print (\"\\n Training faces....\")\n",
    "faces,ids = images_labels(path)\n",
    "recognizer.train(faces, np.array(ids))\n",
    "\n",
    "recognizer.write('trainer/trainer.yml')\n",
    "\n",
    "print(\"\\n {0} faces trained. Exiting Program...\".format(len(np.unique(ids))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Exiting Recognizer...\n"
     ]
    }
   ],
   "source": [
    "# Real time face recognizer\n",
    "\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "#recognizer = cv2.face.BasicFaceRecognizer_create()\n",
    "recognizer.read('trainer/trainer.yml')\n",
    "cascadePath = \"C:\\\\Users\\\\Paras\\\\Anaconda3\\\\envs\\\\py36\\\\Library\\\\etc\\\\haarcascades\\\\haarcascade_frontalface_default.xml\"\n",
    "faceCascade = cv2.CascadeClassifier(cascadePath);\n",
    "\n",
    "font = cv2.FONT_HERSHEY_DUPLEX\n",
    "\n",
    "id = 0\n",
    "\n",
    "# Initialize and start realtime video capture\n",
    "cam = cv2.VideoCapture(0)\n",
    "cam.set(3, 640)\n",
    "cam.set(4, 480)\n",
    "\n",
    "minW = 0.1*cam.get(3)\n",
    "minH = 0.1*cam.get(4)\n",
    "fps = cam.get(5)\n",
    "\n",
    "while True:\n",
    "    ret, img = cam.read()\n",
    "    #url = 'http://192.168.43.125:8080/shot.jpg'\n",
    "    #img_resp = requests.get(url)\n",
    "    #img_arr = np.array(bytearray(img_resp.content), dtype=np.uint8)\n",
    "    #imgg = cv2.imdecode(img_arr, -1)\n",
    "    img = cv2.flip(img, 1)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces = faceCascade.detectMultiScale( \n",
    "        gray,\n",
    "        scaleFactor = 1.2,\n",
    "        minNeighbors = 5,\n",
    "        minSize = (int(minW), int(minH)),\n",
    "       )\n",
    "\n",
    "    for(x,y,w,h) in faces:\n",
    "        cv2.rectangle(img, (x,y), (x+w,y+h), (0,255,255), 2)\n",
    "        id, confidence = recognizer.predict(gray[y:y+h,x:x+w])\n",
    "\n",
    "        # Check if confidence is less them 100 ==> \"0\" is perfect match \n",
    "        if (confidence < 100):\n",
    "            name = label_to_name[id]\n",
    "            confidence = \"  {0}%\".format(round(100 - confidence))\n",
    "        else:\n",
    "            name = \"unknown\"\n",
    "            confidence = \"  {0}%\".format(round(100 - confidence))\n",
    "        \n",
    "        cv2.putText(img, str(name), (x+5,y-5), font, 1, (255,255,255), 2)\n",
    "        #cv2.putText(img, str(confidence), (x+5,y+h-5), font, 1, (255,255,0), 1)  \n",
    "        cv2.putText(img, str(fps), (30,30), font, 1, (255,255,255), 1)\n",
    "    \n",
    "    cv2.imshow('camera',img) \n",
    "    \n",
    "    esc = cv2.waitKey(30) & 0xFF\n",
    "    if esc == 27:\n",
    "        break\n",
    "\n",
    "# Do a bit of cleanup\n",
    "print(\"\\n Exiting Recognizer...\")\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-3be916636dc2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m#ret, img = cap.read()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mimg_resp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mimg_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbytearray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_resp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'allow_redirects'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'get'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    506\u001b[0m         }\n\u001b[0;32m    507\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 508\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    509\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 658\u001b[1;33m             \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    659\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    660\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mcontent\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    821\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    822\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 823\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCONTENT_CHUNK_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_content_consumed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    743\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'stream'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    744\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 745\u001b[1;33m                     \u001b[1;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    746\u001b[0m                         \u001b[1;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\urllib3\\response.py\u001b[0m in \u001b[0;36mstream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    434\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\urllib3\\response.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[0;32m    382\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m                 \u001b[0mcache_content\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Platform-specific: Buggy versions of Python.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m                     \u001b[1;31m# Close the connection when no data is returned\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\http\\client.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    447\u001b[0m             \u001b[1;31m# Amount is given, implement using readinto\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m             \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m             \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\http\\client.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    491\u001b[0m         \u001b[1;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m         \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[1;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import time\n",
    "import requests\n",
    "\n",
    "url = 'http://192.168.0.5:8080/jpg'\n",
    "while True:\n",
    "    #ret, img = cap.read()\n",
    "    img_resp = requests.get(url)\n",
    "    img_arr = np.array(bytearray(img_resp.content), dtype=np.uint8)\n",
    "    img = cv2.imdecode(img_arr, -1)\n",
    "    \n",
    "    cv2.imshow('camera',img)\n",
    "    \n",
    "    esc = cv2.waitKey(30) & 0xFF\n",
    "    if esc == 27:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SOCKET PROGRAMMING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Socket created\n",
      "binding failed\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paras\\Anaconda3\\envs\\py36\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2971: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "import sys\n",
    "\n",
    "host = '192.168.0.2'\n",
    "port = 8888\n",
    "\n",
    "s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "\n",
    "print(\"Socket created\")\n",
    "\n",
    "try:\n",
    "    s.bind((host,port))\n",
    "except socket.error:\n",
    "    print(\"binding failed\")\n",
    "    sys.exit()\n",
    "\n",
    "print(\"Socket has been bounded\")\n",
    "\n",
    "s.listen(10)\n",
    "\n",
    "print(\"socket is ready\")\n",
    "\n",
    "conn, addr = s.accept()\n",
    "print('Connected with '+ addr[0] + \":\" + str(addr[1]))\n",
    "while 1:\n",
    "    data = conn.recv(1024)\n",
    "    print('OK.'+data.decode())\n",
    "    if not data:\n",
    "        break;\n",
    "    conn.sendall(data)\n",
    "    \n",
    "conn.close()\n",
    "s.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    " \n",
    "(major_ver, minor_ver, subminor_ver) = (cv2.__version__).split('.')\n",
    " \n",
    "if __name__ == '__main__' :\n",
    " \n",
    "    # Set up tracker.\n",
    "    # Instead of MIL, you can also use\n",
    " \n",
    "    tracker_types = ['BOOSTING', 'MIL','KCF', 'TLD', 'MEDIANFLOW', 'GOTURN', 'MOSSE', 'CSRT']\n",
    "    tracker_type = tracker_types[1]\n",
    " \n",
    "    if int(minor_ver) < 3:\n",
    "        tracker = cv2.Tracker_create(tracker_type)\n",
    "    else:\n",
    "        if tracker_type == 'BOOSTING':\n",
    "            tracker = cv2.TrackerBoosting_create()\n",
    "        if tracker_type == 'MIL':\n",
    "            tracker = cv2.TrackerMIL_create()\n",
    "        if tracker_type == 'KCF':\n",
    "            tracker = cv2.TrackerKCF_create()\n",
    "        if tracker_type == 'TLD':\n",
    "            tracker = cv2.TrackerTLD_create()\n",
    "        if tracker_type == 'MEDIANFLOW':\n",
    "            tracker = cv2.TrackerMedianFlow_create()\n",
    "        if tracker_type == 'GOTURN':\n",
    "            tracker = cv2.TrackerGOTURN_create()\n",
    "        if tracker_type == 'MOSSE':\n",
    "            tracker = cv2.TrackerMOSSE_create()\n",
    "        if tracker_type == \"CSRT\":\n",
    "            tracker = cv2.TrackerCSRT_create()\n",
    " \n",
    "    # Read video\n",
    "    video = cv2.VideoCapture(0)\n",
    " \n",
    "    # Exit if video not opened.\n",
    "    if not video.isOpened():\n",
    "        print (\"Could not open video\")\n",
    "        sys.exit()\n",
    " \n",
    "    # Read first frame.\n",
    "    ok, frame = video.read()\n",
    "    if not ok:\n",
    "        print ('Cannot read video file')\n",
    "        sys.exit()\n",
    "     \n",
    "    # Define an initial bounding box\n",
    "    #bbox = (287, 23, 86, 320)\n",
    " \n",
    "    # Uncomment the line below to select a different bounding box\n",
    "    bbox = cv2.selectROI(frame, False)\n",
    " \n",
    "    # Initialize tracker with first frame and bounding box\n",
    "    ok = tracker.init(frame, bbox)\n",
    " \n",
    "    while True:\n",
    "        # Read a new frame\n",
    "        ok, frame = video.read()\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        if not ok:\n",
    "            break\n",
    "         \n",
    "        # Start timer\n",
    "        timer = cv2.getTickCount()\n",
    " \n",
    "        # Update tracker\n",
    "        ok, bbox = tracker.update(frame)\n",
    " \n",
    "        # Calculate Frames per second (FPS)\n",
    "        fps = cv2.getTickFrequency() / (cv2.getTickCount() - timer);\n",
    " \n",
    "        # Draw bounding box\n",
    "        if ok:\n",
    "            # Tracking success\n",
    "            p1 = (int(bbox[0]), int(bbox[1]))\n",
    "            p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "            cv2.rectangle(frame, p1, p2, (255,0,0), 2, 1)\n",
    "        else :\n",
    "            # Tracking failure\n",
    "            cv2.putText(frame, \"Tracking failure detected\", (100,80), cv2.FONT_HERSHEY_SIMPLEX, 0.75,(0,0,255),2)\n",
    " \n",
    "        # Display tracker type on frame\n",
    "        cv2.putText(frame, tracker_type + \" Tracker\", (100,20), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (50,170,50),2);\n",
    "     \n",
    "        # Display FPS on frame\n",
    "        cv2.putText(frame, \"FPS : \" + str(int(fps)), (100,50), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (50,170,50), 2);\n",
    " \n",
    "        # Display result\n",
    "        cv2.imshow(\"Tracking\", frame)\n",
    " \n",
    "        # Exit if ESC pressed\n",
    "        k = cv2.waitKey(30) & 0xff\n",
    "        if k == 27:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2018 Satya Mallick (LearnOpenCV.com)\n",
    "\n",
    "# Import modules\n",
    "import cv2, sys, os\n",
    "\n",
    "if  not (os.path.isfile('goturn.caffemodel') and os.path.isfile('goturn.prototxt')):\n",
    "    errorMsg = '''\n",
    "    Could not find GOTURN model in current directory.\n",
    "    Please ensure goturn.caffemodel and goturn.prototxt are in the current directory\n",
    "    '''\n",
    "\n",
    "    print(errorMsg)\n",
    "    sys.exit()\n",
    "\n",
    "# Create tracker\n",
    "tracker = cv2.TrackerGOTURN_create()   \n",
    "\n",
    "# Read video\n",
    "video = cv2.VideoCapture(0)\n",
    "\n",
    "# Exit if video not opened\n",
    "if not video.isOpened():\n",
    "    print(\"Could not open video\")\n",
    "    sys.exit()\n",
    "\n",
    "# Read first frame\n",
    "ok,frame = video.read()\n",
    "if not ok:\n",
    "    print(\"Cannot read video file\")\n",
    "    sys.exit()\n",
    "\n",
    "\n",
    "# Define a bounding box\n",
    "bbox = (276, 23, 86, 320)\n",
    "\n",
    "# Uncomment the line below to select a different bounding box\n",
    "#bbox = cv2.selectROI(frame, False)\n",
    "\n",
    "# Initialize tracker with first frame and bounding box\n",
    "ok = tracker.init(frame,bbox)\n",
    "\n",
    "while True:\n",
    "    # Read a new frame\n",
    "    ok, frame = video.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    if not ok:\n",
    "        break\n",
    "\n",
    "    # Start timer\n",
    "    timer = cv2.getTickCount()\n",
    "\n",
    "    # Update tracker\n",
    "    ok, bbox = tracker.update(frame)\n",
    "\n",
    "    # Calculate Frames per second (FPS)\n",
    "    fps = cv2.getTickFrequency() / (cv2.getTickCount() - timer);\n",
    "\n",
    "    # Draw bounding box\n",
    "    if ok:\n",
    "        # Tracking success\n",
    "        p1 = (int(bbox[0]), int(bbox[1]))\n",
    "        p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "        cv2.rectangle(frame, p1, p2, (255,0,0), 2, 1)\n",
    "    else :\n",
    "        # Tracking failure\n",
    "        cv2.putText(frame, \"Tracking failure detected\", (100,80), cv2.FONT_HERSHEY_SIMPLEX, 0.75,(0,0,255),2)\n",
    "\n",
    "    # Display tracker type on frame\n",
    "    cv2.putText(frame, \"GOTURN Tracker\", (100,20), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (50,170,50),2);\n",
    "\n",
    "    # Display FPS on frame\n",
    "    cv2.putText(frame, \"FPS : \" + str(int(fps)), (100,50), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (50,170,50), 2);\n",
    "\n",
    "    # Display result\n",
    "    cv2.imshow(\"Tracking\", frame)\n",
    " \n",
    "    # Exit if ESC pressed\n",
    "    k = cv2.waitKey(1) & 0xff\n",
    "    if k == 27:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
